{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d1a7fe3",
   "metadata": {},
   "source": [
    "Welcome to one of the collaborative Jupyter/Spark environments in ZHAW. You are not yet connected to Sparky by default. However, the necessary code template makes this a quick process. Keep in mind that you are sharing both the Jupyter environment and the Sparky cluster with others. Custom Python packages on the notebook/Spark driver side are installed with %pip install."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7c9df5",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29c65218",
   "metadata": {},
   "outputs": [],
   "source": [
    "zhawaccount = \"tsianthe\"  # TODO set this to your ZHAW-KÃ¼rzel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78b55c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~ Sparky module loaded ~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/24 13:31:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/06/24 13:31:11 WARN Utils: Service 'sparkDriver' could not bind on port 5555. Attempting port 5556.\n",
      "24/06/24 13:31:11 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 4444. Attempting port 4445.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attached to Sparky cluster context from sparky-collab as sparknotebook-tsianthe.\n",
      "Requested 2 cores; real number might be less.\n"
     ]
    }
   ],
   "source": [
    "import sparky\n",
    "import pyspark\n",
    "#import slash\n",
    "import pyspark.sql\n",
    "sc = sparky.connect(f\"sparknotebook-{zhawaccount}\", 2)\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "866a0f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.4\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "344ff206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dd534d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to read: 6.41 seconds\n"
     ]
    }
   ],
   "source": [
    "# Read csv-files\n",
    "read_time = time.time()\n",
    "df_customer = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"Customermaster.csv\")\n",
    "df_items = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"Itemmaster.csv\")\n",
    "df_orders = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"Orderlines.csv\")\n",
    "df_currate = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"ExchangeRates.csv\")\n",
    "read_time_finish = time.time()\n",
    "print(f\"Time taken to read: {read_time_finish - read_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "097bd7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Data\n",
    "from pyspark.sql.functions import trim, col, to_date, when\n",
    "\n",
    "# Customer ---------------------------\n",
    "df_customer = df_customer.withColumn(\"Status\", col(\"Status\").cast(\"integer\"))\n",
    "df_customer = df_customer.withColumn(\"Potential\", col(\"Potential\").cast(\"float\"))\n",
    "df_customer = df_customer.withColumn(\"Entry Date\", to_date(col(\"Entry Date\"), \"yyyyMMdd\"))\n",
    "\n",
    "# Item ---------------------------\n",
    "df_items = df_items.withColumn(\"Item number\", trim(df_items[\"Item number\"]))\n",
    "df_items = df_items.withColumn(\"Itemgroup\", trim(df_items[\"Itemgroup\"]))\n",
    "df_items = df_items.withColumn(\"Itemgroup\", col(\"Itemgroup\").cast(\"integer\"))\n",
    "df_items = df_items.withColumn(\"Productgroup\", trim(df_items[\"Productgroup\"]))\n",
    "df_items = df_items.withColumn(\"Itemtype\", trim(df_items[\"Itemtype\"]))\n",
    "\n",
    "# Define mapping dictionary for renaming\n",
    "rename_map = {\n",
    "    \"1000\": \"Valve\",\n",
    "    \"1100\": \"Actuator\",\n",
    "    \"1200\": \"Fitting\",\n",
    "    \"1300\": \"Instrumentation\",\n",
    "    \"1400\": \"Air Line Equipment\",\n",
    "    \"1500\": \"Vacuum Unit\",\n",
    "    \"1600\": \"Heat Exchanger\",\n",
    "    \"1700\": \"Hydraulics\",\n",
    "    \"1800\": \"Filter\",\n",
    "    \"1900\": \"Other\",\n",
    "    \"\": \"Other\",\n",
    "    \"2000\": \"3rdParty\"\n",
    "}\n",
    "\n",
    "# Rename values in the \"Itemgroup\" column based on the mapping dictionary\n",
    "#df_items = df_items.withColumn(\"Itemgroup\", \n",
    "#                    when(col(\"Itemgroup\").isin(list(rename_map.keys())), \n",
    "#                         rename_map[col(\"Itemgroup\")]).otherwise(col(\"Itemgroup\")))\n",
    "\n",
    "# Order ---------------------------\n",
    "df_orders = df_orders.withColumn(\"Customernumber\", trim(df_orders[\"Customernumber\"]))\n",
    "df_orders = df_orders.withColumn(\"Item number\", trim(df_orders[\"Item number\"]))\n",
    "df_orders = df_orders.withColumn(\"Status\", col(\"Status\").cast(\"integer\"))\n",
    "df_orders = df_orders.withColumn(\"Net price\", col(\"Net price\").cast(\"float\"))\n",
    "\n",
    "quantity_columns = [\n",
    "    \"Ordered quantity\", \"Confirmed quantity\", \"Remaining quantity\", \n",
    "    \"Allocated quantity\", \"Picking list quantity\", \n",
    "    \"Delivered quantity\", \"Invoiced quantity\"\n",
    "]\n",
    "\n",
    "for column in quantity_columns:\n",
    "    df_orders = df_orders.withColumn(column, col(column).cast(\"integer\"))\n",
    "    \n",
    "date_columns = [\n",
    "    \"Requested delivery date\", \"Confirmed delivery date\", \n",
    "    \"Departure date\", \"Planning date\", \"Registration date\"\n",
    "]\n",
    "\n",
    "for column in date_columns:\n",
    "    df_orders = df_orders.withColumn(column, to_date(col(column), \"yyyyMMdd\"))\n",
    "\n",
    "# Exchange Rate ---------------------------\n",
    "df_currate = df_currate.withColumn(\"ExchangeRate\", col(\"ExchangeRate\").cast(\"float\"))\n",
    "df_currate = df_currate.withColumn(\"ActiveDate\", to_date(col(\"ActiveDate\"), \"yyyyMMdd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "064de37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Store the files in Parquet format \n",
    "df_customer.write.mode(\"overwrite\").parquet(\"./customermaster.parquet\")\n",
    "df_items.write.mode(\"overwrite\").parquet(\"./itemmaster.parquet\")\n",
    "df_orders.write.mode(\"overwrite\").parquet(\"./orderlines.parquet\")\n",
    "df_currate.write.mode(\"overwrite\").parquet(\"./exchangerates.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ae174e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to read: 0.86 seconds\n"
     ]
    }
   ],
   "source": [
    "# Read parquet-files\n",
    "read_time_start = time.time()\n",
    "df_customer_p = spark.read.parquet(\"./customermaster.parquet\", header=True, inferSchema=True)\n",
    "df_items_p = spark.read.parquet(\"./itemmaster.parquet\", header=True, inferSchema=True)\n",
    "df_orders_p = spark.read.parquet(\"./orderlines.parquet\", header=True, inferSchema=True)\n",
    "df_currate_p = spark.read.parquet(\"./exchangerates.parquet\", header=True, inferSchema=True)\n",
    "read_time_finish = time.time()\n",
    "print(f\"Time taken to read: {read_time_finish - read_time_start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63f33128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in customer: 39250\n",
      "\n",
      "Number of records in items: 2226456\n",
      "\n",
      "Number of records in orders: 465209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Return the number of records per file.\n",
    "record_count = df_customer_p.count()\n",
    "print(f\"Number of records in customer: {record_count}\\n\")\n",
    "record_count = df_items_p.count()\n",
    "print(f\"Number of records in items: {record_count}\\n\")\n",
    "record_count = df_orders_p.count()\n",
    "print(f\"Number of records in orders: {record_count}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59d6d484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Customernumber='K072870000', Status=10, CGC='XXX', Industry='M', Potential=2000.0, DiscountModel='SMCSTDCHFA', PriceList='STDPRICE  ', Currency='CHF', TargetFlag=' ', IndirectFlag=' ', Oldcustomernr='          ', Newcustomernr='K01286JIT0', Incoterms='EXW', CRMflag='5', CRMID='6dcfddfa-1c83-11ee-98f4-0050568cbcf8', SPC='KM03', Entry Date=datetime.date(2023, 7, 6))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customer_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ce90be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Item number='02419283', Status='20', Itemgroup=1900, Productgroup='999', Itemtype='2', EntryDate='20220412', Responsible='LOCAL ES  ')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_items_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f20ab20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Company='100', Division='CH0', Customernumber='K022520000', CustomerOrderNumber='0100832280', Linenumber='1', LineSuffix='0', Status=5, Facility='K01', Warehouse='K01', Item number='01741721', Ordered quantity=1, Confirmed quantity=0, Remaining quantity=1, Allocated quantity=0, Picking list quantity=0, Delivered quantity=0, Invoiced quantity=0, Net price=396.7223205566406, Requested delivery date=datetime.date(2022, 4, 4), Confirmed delivery date=datetime.date(2022, 4, 4), Departure date=datetime.date(2022, 4, 4), Planning date=datetime.date(2022, 4, 4), Registration date=datetime.date(2022, 3, 29))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df0a89e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ActiveDate=datetime.date(2021, 9, 30), LocalCurrency='CHF', ForeignCurrency='USD', ExchangeRate=0.8956999778747559),\n",
       " Row(ActiveDate=datetime.date(2022, 3, 31), LocalCurrency='CHF', ForeignCurrency='USD', ExchangeRate=0.8956999778747559),\n",
       " Row(ActiveDate=datetime.date(2020, 3, 24), LocalCurrency='CHF', ForeignCurrency='USD', ExchangeRate=0.9300000071525574),\n",
       " Row(ActiveDate=datetime.date(2021, 7, 29), LocalCurrency='CHF', ForeignCurrency='ZAR', ExchangeRate=0.06333500146865845),\n",
       " Row(ActiveDate=datetime.date(2021, 11, 4), LocalCurrency='CHF', ForeignCurrency='ZAR', ExchangeRate=0.05507500097155571)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_currate_p.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe21520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer_p.createOrReplaceTempView(\"customer\")\n",
    "df_items_p.createOrReplaceTempView(\"items\")\n",
    "df_orders_p.createOrReplaceTempView(\"orders\")\n",
    "df_currate_p.createOrReplaceTempView(\"exchangerate\")\n",
    "df_customer.createOrReplaceTempView(\"customerCSV\")\n",
    "df_items.createOrReplaceTempView(\"itemsCSV\")\n",
    "df_orders.createOrReplaceTempView(\"ordersCSV\")\n",
    "df_currate.createOrReplaceTempView(\"exchangerateCSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41abee2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|UniqueItems|\n",
      "+-----------+\n",
      "|      39231|\n",
      "+-----------+\n",
      "\n",
      "Time taken to read: 0.11 seconds\n"
     ]
    }
   ],
   "source": [
    "# Count unique sold Items - does not work?\n",
    "read_time_start = time.time()\n",
    "result = spark.sql(\"\"\"Select Count(Distinct `Item number`) as UniqueItems From orders\"\"\")\n",
    "read_time_finish = time.time()\n",
    "result.show()\n",
    "print(f\"Time taken to read: {read_time_finish - read_time_start:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30bcc515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|CountOrderLines|\n",
      "+---------------+\n",
      "|          93069|\n",
      "+---------------+\n",
      "\n",
      "Time taken to read: 0.08 seconds\n"
     ]
    }
   ],
   "source": [
    "# Count Orderlines in CHF in 2021 in CHF\n",
    "read_time_start = time.time()\n",
    "result = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    Count(or.`Customernumber`) as CountOrderLines\n",
    "FROM \n",
    "    orders as or\n",
    "LEFT JOIN \n",
    "    customer as cu\n",
    "ON\n",
    "    or.Customernumber = cu.Customernumber\n",
    "WHERE\n",
    "    cu.Currency = 'CHF' AND\n",
    "    or.Status > 5 and or.Status < 90 AND\n",
    "    or.`Registration date` BETWEEN '2021-01-01' AND '2021-12-31'\n",
    "\"\"\")\n",
    "read_time_finish = time.time()\n",
    "result.show()\n",
    "print(f\"Time taken to read: {read_time_finish - read_time_start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62be2d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "| MioOrderAmountCHF|\n",
      "+------------------+\n",
      "|19.785846694221533|\n",
      "+------------------+\n",
      "\n",
      "Time taken to read: 0.05 seconds\n"
     ]
    }
   ],
   "source": [
    "# Overall Orderamount in 2021 with CHF-Customers\n",
    "read_time_start = time.time()\n",
    "result = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    SUM(`Ordered quantity` * `Net price`)/1000000 as MioOrderAmountCHF\n",
    "FROM \n",
    "    orders as or\n",
    "LEFT JOIN \n",
    "    customer as cu\n",
    "ON\n",
    "    or.Customernumber = cu.Customernumber\n",
    "WHERE\n",
    "    cu.Currency = 'CHF' AND\n",
    "    or.Status > 5 AND or.Status < 90 AND\n",
    "    or.`Registration date` BETWEEN '2021-01-01' AND '2021-12-31' \"\"\")\n",
    "read_time_finish = time.time()\n",
    "result.show()\n",
    "print(f\"Time taken to read: {read_time_finish - read_time_start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d7ccbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+---------------+------------+------+\n",
      "|ActiveDate|LocalCurrency|ForeignCurrency|ExchangeRate|rankno|\n",
      "+----------+-------------+---------------+------------+------+\n",
      "|2021-07-29|          CHF|            CZK|    0.043715|     1|\n",
      "|2022-05-31|          CHF|            DKK|     0.13163|     1|\n",
      "|2022-04-30|          CHF|            DKK|    0.131223|     2|\n",
      "|2022-03-31|          CHF|            DKK|    0.130946|     3|\n",
      "|2022-03-31|          CHF|            DKK|    0.130219|     3|\n",
      "|2022-01-31|          CHF|            DKK|    0.125392|     4|\n",
      "|2021-12-31|          CHF|            DKK|    0.124247|     5|\n",
      "|2021-11-30|          CHF|            DKK|    0.128267|     6|\n",
      "|2021-10-31|          CHF|            DKK|    0.128699|     7|\n",
      "|2021-09-30|          CHF|            DKK|    0.129661|     8|\n",
      "|2021-09-30|          CHF|            DKK|    0.130219|     8|\n",
      "|2021-08-31|          CHF|            DKK|    0.128605|     9|\n",
      "|2021-07-31|          CHF|            DKK|    0.129064|    10|\n",
      "|2021-07-29|          CHF|            DKK|    0.160615|    11|\n",
      "|2021-06-30|          CHF|            DKK|    0.131428|    12|\n",
      "|2021-05-31|          CHF|            DKK|    0.130558|    13|\n",
      "|2021-04-30|          CHF|            DKK|       0.132|    14|\n",
      "|2021-03-31|          CHF|            DKK|    0.133825|    15|\n",
      "|2021-03-31|          CHF|            DKK|    0.133424|    15|\n",
      "|2021-02-28|          CHF|            DKK|    0.133619|    16|\n",
      "+----------+-------------+---------------+------------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Time taken to read: 0.06 seconds\n"
     ]
    }
   ],
   "source": [
    "# Select only latest Exchange-Rates due to ranking\n",
    "read_time_start = time.time()\n",
    "result = spark.sql(\"\"\"\n",
    "Select *, \n",
    "dense_rank() over (Partition by ForeignCurrency Order By ActiveDate desc) as rankno\n",
    "From exchangerate\n",
    "where ForeignCurrency != 'CHF' \"\"\")\n",
    "read_time_finish = time.time()\n",
    "result.show()\n",
    "print(f\"Time taken to read: {read_time_finish - read_time_start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6ba82a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "| MioOrderAmountCHF|\n",
      "+------------------+\n",
      "|30.322033072304457|\n",
      "+------------------+\n",
      "\n",
      "Time taken to read: 0.05 seconds\n"
     ]
    }
   ],
   "source": [
    "# Overall Orderamount in 2021 with all-Customers and latest Exchange Rate\n",
    "read_time_start = time.time()\n",
    "result = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    SUM(or.`Ordered quantity` * or.`Net price` * ra.ExchangeRate)/1000000 as MioOrderAmountCHF\n",
    "FROM \n",
    "    orders as or\n",
    "LEFT JOIN \n",
    "    customer as cu\n",
    "ON\n",
    "    or.Customernumber = cu.Customernumber\n",
    "LEFT JOIN \n",
    "    (SELECT * \n",
    "        FROM(\n",
    "        SELECT\n",
    "            ActiveDate,\n",
    "            ForeignCurrency,\n",
    "            ExchangeRate,\n",
    "            dense_rank() over (Partition by ForeignCurrency Order By ActiveDate desc) as rankno\n",
    "        From \n",
    "            exchangerate) as exchrate\n",
    "    WHERE \n",
    "        exchrate.rankno = 1) as ra\n",
    "ON\n",
    "    cu.Currency = ra.ForeignCurrency\n",
    "WHERE\n",
    "    or.Status > 5 AND or.Status < 90 AND\n",
    "    or.`Registration date` BETWEEN '2021-01-01' AND '2021-12-31' \"\"\")\n",
    "read_time_finish = time.time()\n",
    "result.show()\n",
    "print(f\"Time taken to read: {read_time_finish - read_time_start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9136936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|Itemgroup|   MioOrderAmountCHF|\n",
      "+---------+--------------------+\n",
      "|     1700| 0.02216495757484436|\n",
      "|     1500|  0.9129024241651148|\n",
      "|     1300|  1.1374349568749667|\n",
      "|     1400|   3.483150809136237|\n",
      "|     1100|   6.784189984872997|\n",
      "|     1800|0.030853060820102692|\n",
      "|     1600|  1.6795161772317886|\n",
      "|     1000|   6.633493100238214|\n",
      "|     1200|  3.3430149478758806|\n",
      "|     2000|6.037993450164795E-4|\n",
      "|     1900|   6.294708854169264|\n",
      "+---------+--------------------+\n",
      "\n",
      "Time taken to read: 0.07 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Overall Orderamount in 2021 with all-Customers and latest Exchange Rate by Itemgroup\n",
    "read_time_start = time.time()\n",
    "result = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    it.`Itemgroup`,\n",
    "    SUM(or.`Ordered quantity` * or.`Net price` * COALESCE(ra.ExchangeRate, 1)) / 1000000 as MioOrderAmountCHF\n",
    "FROM \n",
    "    orders as or\n",
    "LEFT JOIN \n",
    "    customer as cu\n",
    "ON\n",
    "    or.Customernumber = cu.Customernumber\n",
    "LEFT JOIN \n",
    "    (SELECT\n",
    "        ForeignCurrency,\n",
    "        ExchangeRate,\n",
    "        dense_rank() over (Partition by ForeignCurrency Order By ActiveDate desc) as rankno\n",
    "     FROM \n",
    "        exchangerate\n",
    "    ) AS ra\n",
    "ON\n",
    "    cu.Currency = ra.ForeignCurrency AND ra.rankno = 1\n",
    "LEFT JOIN\n",
    "    items as it\n",
    "ON\n",
    "    or.`Item number` = it.`Item number`\n",
    "WHERE\n",
    "    or.Status > 5 AND or.Status < 90 AND\n",
    "    or.`Registration date` BETWEEN '2021-01-01' AND '2021-12-31'\n",
    "GROUP BY\n",
    "    it.`Itemgroup`\"\"\")\n",
    "read_time_finish = time.time()\n",
    "result.show()\n",
    "print(f\"Time taken to read: {read_time_finish - read_time_start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08378aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3188d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
